{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object.\n",
    "llama = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Good evening! It's great to chat with you. How's your night going so far?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can call model's invoke method to directly chat with the model.\n",
    "llama.invoke(\"Good Evening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get it,\n",
      " you're frustrated with the consultant's lack of insight or value-add.\n",
      " Before we dive into potential ways to express your concerns (or \"insult\" them,\n",
      " as you put it), let me offer some context and suggestions:\n",
      "\n",
      "1.\n",
      " **Take a deep breath**: Remember that the consultant is just doing their job,\n",
      " and it's not personal.\n",
      "2.\n",
      " **Focus on the issue,\n",
      " not the person**: Instead of attacking the consultant's character or intelligence,\n",
      " address specific concerns about their work.\n",
      "\n",
      "That being said,\n",
      " if you still want to express your frustration in a meeting,\n",
      " here are some tips:\n",
      "\n",
      "**Before the meeting:**\n",
      "\n",
      "1.\n",
      " Prepare specific examples of what didn't meet your expectations.\n",
      "2.\n",
      " Consider sharing positive experiences with other consultants or internal teams to maintain perspective.\n",
      "\n",
      "**During the meeting:**\n",
      "\n",
      "1.\n",
      " **Use \"I\" statements**: Start sentences with \"I feel\" or \"I think\" to express your concerns without attacking the consultant.\n",
      "Example: \"I feel frustrated when I don't see clear progress on this project.\"\n",
      "2.\n",
      " **Be specific about what's not working**: Avoid generalizations like \"You're terrible at [X].\" Instead,\n",
      " say something like:\n",
      "\t* \"I'm concerned that our last meeting didn't seem to lead to actionable next steps.\n",
      " Can you explain how we'll move forward?\"\n",
      "3.\n",
      " **Ask open-ended questions**: Encourage the consultant to think critically and share their perspective.\n",
      "Example: \"Can you walk me through your thought process on [specific topic]?\"\n",
      "\n",
      "**Potential (carefully crafted) criticisms:**\n",
      "\n",
      "1.\n",
      " **\"I'm not seeing the value\":** Express that you're struggling to see how the consultant's recommendations or approach will benefit your organization.\n",
      "2.\n",
      " **\"Lack of clarity\":** Share that you need more transparency or concrete plans to understand the consultant's strategy.\n",
      "3.\n",
      " **\"Inconsistent delivery\":** Mention that you've noticed variations in quality,\n",
      " responsiveness,\n",
      " or communication style from one meeting to another.\n",
      "\n",
      "Remember to maintain a professional tone and avoid personal attacks.\n",
      " Your goal is to stimulate constructive dialogue,\n",
      " not to \"insult\" the consultant.\n",
      "\n",
      "If you're still looking for ways to express your frustration without being too harsh,\n",
      " consider having a separate conversation with your manager or HR representative.\n",
      " They can help mediate the situation and provide guidance on how to address concerns in a productive manner.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What do to with stupid consultants? dont be formal just be real how can I insult him in a meeting.\"\n",
    "line = ''\n",
    "\n",
    "\n",
    "# If we want to stream output line by line.\n",
    "for chunk in llama.stream(query):\n",
    "    if chunk == ',' or chunk == '.' or chunk == '\\n':\n",
    "        line += chunk\n",
    "        print(line)\n",
    "        time.sleep(1.3)\n",
    "        line = \"\"\n",
    "    \n",
    "    else:\n",
    "        line += chunk\n",
    "\n",
    "print(line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# result = llama.invoke('hello!')\n",
    "\n",
    "# parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain string output parser and model to use single invoke method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llama | parser\n",
    "chain.invoke('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koala-JTGF2TUf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
